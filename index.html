<!DOCTYPE html>
<!-- saved from url=(0029)https://junshutang.github.io/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><style type="text/css">
  /* 全局基础样式 */
  body {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 15px;
    line-height: 1.6;
    color: #333;
    background-color: #fff;
    margin: 0;
  }

  /* 链接样式优化 */
  a {
    color: #0066cc;
    text-decoration: none;
    transition: all 0.2s ease;
  }
  a:hover {
    color: #004499;
    text-decoration: underline;
  }

  /* 个人名字样式 */
  name {
    font-size: 30px;
    font-weight: 700;
    display: inline-block;
    color: #111;
    margin-bottom: 5px;
    letter-spacing: -0.5px;
  }

  /* 标题 Heading 样式 */
  heading {
    font-size: 22px;
    font-weight: 700;
    color: #111;
    display: block;
    margin-top: 30px;
    margin-bottom: 20px;
    padding-bottom: 10px;
    border-bottom: 1px solid #f0f0f0;
    letter-spacing: 0.5px;
  }

  /* 论文标题样式 */
  papertitle {
    font-size: 17px;
    font-weight: 700;
    color: #1a1a1a;
    display: block;
    margin-bottom: 6px;
    line-height: 1.35;
  }

  /* 作者列表中的自己 */
  strong {
    color: #000;
    font-weight: 700;
  }

  /* 图片通用样式：圆角与阴影 */
  img {
    border-radius: 6px;
    transition: all 0.3s ease;
  }

  /* 论文缩略图悬停效果 */
  td[style*="25%"] img {
    box-shadow: 0 2px 5px rgba(0,0,0,0.05);
  }
  td[style*="25%"] img:hover {
    box-shadow: 0 5px 15px rgba(0,0,0,0.15);
    transform: translateY(-2px);
  }

  /* 头像悬停效果 */
  .hoverZoomLink:hover {
    box-shadow: 0 5px 15px rgba(0,0,0,0.15);
    transform: scale(1.02);
  }

  /* Spotlight 标签优化 */
  span[style*="color: red"] {
    color: #c92a2a !important; /* 更深沉的红色 */
    background-color: #fff5f5;
    padding: 2px 8px;
    border-radius: 12px;
    font-size: 0.85em;
    font-weight: bold;
    border: 1px solid #ffc9c9;
  }

  /* 调整表格单元格间距 */
  td {
    padding-top: 10px !important;
    padding-bottom: 10px !important;
  }

  /* 针对论文列表的特定调整 */
  table tbody tr td[style*="75%"] {
    font-size: 15px;
    line-height: 1.6;
    vertical-align: top !important; /* 顶对齐通常看起来更整洁 */
    padding-top: 20px !important; /* 增加一点顶部间距 */
  }

  /* News 列表优化 */
  ul {
    padding-left: 20px;
    margin-top: 5px;
  }
  li {
    margin-bottom: 6px;
    color: #444;
  }

  /* Ant Design Icon 样式保留 (如果需要) */
  .anticon { display: inline-block; color: inherit; font-style: normal; line-height: 0; text-align: center; text-transform: none; vertical-align: -0.125em; text-rendering: optimizeLegibility; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; }
  .anticon > * { line-height: 1; }
  .anticon svg { display: inline-block; }
  .anticon::before { display: none; }
  .anticon .anticon-icon { display: block; }
</style>

  <title> Jinkun Hao (郝锦坤) </title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-site-verification" content="A2nXUugMvMH5Xy0yLCrnLyU0jySYHhQGTZwju8WLFCk">
  <link rel="stylesheet" type="text/css" href="./static/stylesheet.css">
  <link href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap" rel="stylesheet">
  <link rel="dns-prefetch" href="https://fonts.googleapis.com/">
  <link rel="dns-prefetch" href="https://fonts.gstatic.com/">
  <link rel="dns-prefetch" href="https://www.google-analytics.com/">
</head>

<body data-new-gr-c-s-check-loaded="14.1193.0" data-gr-ext-installed="">
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jinkun Hao (郝锦坤) </name>  <br> <br>
              </p>
              <p style="font-family:verdana"> I am now a forth year Ph.D. student at the Shanghai Jiao Tong University (<a href="https://www.sjtu.edu.cn/">SJTU</a>), advised by <a href="https://dmcv.sjtu.edu.cn/">Lizhuang Ma</a> and <a href="https://yiranran.github.io/">Ran yi</a>. 
                <br> I currently focused on Generative Simulation and Embodied AI. My current work involves leveraging video generation models to bridge the gap between embodied agents and environment interactions. Simultaneously, I am building an automated 3D world generation system powered by code-generation agents.  
              </p>
 
 
              <p style="text-align:center">
                <a href="leo_hao@sjtu.edu.cn"> Email</a> &nbsp;/&nbsp;
                <a href="https://github.com/jinkun-hao"> Github</a> &nbsp;/&nbsp; 
                <a href="https://scholar.google.com/citations?user=CJNkSiUAAAAJ&hl=zh-CN">Google Scholar</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
             <img style="width:100%;max-width:100%" alt="profile photo" src="./static/picture.png" class="hoverZoomLink">
            </td>
          </tr>
        </tbody></table>
                                                                                                                          
                                                                                                                          
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                </tbody><tbody>
                  <tr>
                    <td>
                      <heading>News</heading>
                      <p>
                      </p><ul>
      <li><strong>News (Sep 2025): One paper MesaTask is accepted to NeurIPS 2025 as Spotlight</aside>.</strong></li>
      <li>News (June 2025): One paper is accepted to ICCV 2025.</li>
			<li>News (Dec 2024): One paper is accepted to AAAI 2025.</li>
                      </ul>
                      <p></p>
                    </td>
                  </tr>
                </tbody>
        </table>
 
        <heading>Publications</heading>
        <!-- <p> (* indicates joint first authors) </p> -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:30px;width:25%;vertical-align:middle">
              <img src="./static/RoboVIP.png" width="240" height="140">
            </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                          <papertitle>RoboVIP: Multi-View Video Generation with Visual Identity Prompting Augments Robot Manipulation</papertitle>
                          <br>
                          Boyang Wang, Haoran Zhang, Shujie Zhang, <strong>Jinkun Hao</strong>, Mingda Jia, Qi Lv,  Yucheng Mao, Zhaoyang Lyu, Jia Zeng, Xudong Xu, Jiangmiao Pang
              <br>
              <strong><em>Arxiv</em>, 2026 </strong>
                          <br>
              <a href="https://mesatask.github.io/">project page</a>
                          /
                          <a href="https://arxiv.org/abs/2509.22281">paper</a>
                          /
                          <a href="https://github.com/InternRobotics/MesaTask">code</a>
                          <p></p>
                          <p></p>
                        </td>
                      </tr>

          </tr>

          <tr>
            <td style="padding:30px;width:25%;vertical-align:middle">
              <img src="./static/MesaTask.jpg" width="240" height="140">
            </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                          <papertitle>MesaTask: Towards Task-Driven Tabletop Scene Generation via 3D Spatial Reasoning</papertitle>
                          <br>
                          <strong>Jinkun Hao</strong>*, Naifu Liang*, Zhen Luo*, Xudong Xu‡, Weipeng Zhong, Ran Yi, Yichen Jin, Zhaoyang Lyu, Feng Zheng, Lizhuang Ma, Jiangmiao Pang
              <br>
              <strong><em>NeurIPS</em>, 2025 (<span style="color: red;">Spotlight (Top 2%)</span>)</strong>
                          <br>
              <a href="https://robovip.github.io/RoboVIP/">project page</a>
                          /
                          <a href="https://arxiv.org/abs/2601.05241">paper</a>`
                          /
                          <a href="https://robovip.github.io/RoboVIP/">code</a>
                          <p></p>
                          <p></p>
                        </td>
                      </tr>

          </tr>

          <tr>
            <td style="padding:30px;width:25%;vertical-align:middle">
              <img src="./static/Stylized-Face.png" width="240" height="140">
            </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                          <papertitle>Stylized-Face: A Million-level Stylized Face Dataset for Face Recognition</papertitle>
                          <br>
                          Zhengyuan Peng, Jianqing Xu, Yuge Huang, <strong>Jinkun Hao</strong>, Shouhong Ding, Zhizhong Zhang, Xin Tan, Lizhuang Ma
              <br>
                                        <strong><em>ICCV</em>, 2025</strong>
                                        <br>
                                        <a href="https://openaccess.thecvf.com/content/ICCV2025/papers/Peng_Stylized-Face_A_Million-level_Stylized_Face_Dataset_for_Face_Recognition_ICCV_2025_paper.pdf">paper</a>
                          <br>
                        </td>
                      </tr>

          </tr>

          <tr>
            <td style="padding:30px;width:25%;vertical-align:middle">
              <img src="./static/ID-Sculpt.jpg" width="240" height="140">
            </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                          <papertitle>ID-Sculpt: ID-aware 3D Head Generation from Single In-the-wild Portrait Image</papertitle>
                          <br>
                          <strong>Jinkun Hao</strong>, Junshu Tang, Jiangning Zhang, Ran Yi, Yijia Hong, Moran Li, Weijian Cao, Yating Wang, Chengjie Wang, Lizhuang Ma
              <br>
                                        <strong><em>AAAI</em>, 2025 </strong>
                          <br>
              <a href="https://jinkun-hao.github.io/IDSculpt/">project page</a>
                          /
                          <a href="https://arxiv.org/abs/2406.16710">paper</a>
                          /
                          <a href="https://github.com/jinkun-hao/ID-Sculpt">code</a>
                          <p></p>
                          <p></p>
                        </td>
                      </tr>

          </tr>

          <tr>
            <td style="padding:30px;width:25%;vertical-align:middle">
              <img src="./static/clothdreamer.png" width="240" height="140">
            </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                          <papertitle>Semi-supervised 3d object detection via adaptive pseudo-labeling</papertitle>
                          <br>
                          Yufei Liu, Junshu Tang, Zheng Chu, Shijie Zhang, <strong>Jinkun Hao</strong>, Junwei Zhu, Dongjin Huang
              <br>
                                        <em>Arxiv</em>, 2024 
                          <br>
              <a href="https://ggxxii.github.io/clothedreamer/">project page</a>
                          /
                          <a href="https://arxiv.org/pdf/2406.16815">paper</a>
                          /
                          <a href="https://github.com/ggxxii/clothedreamert">code</a>
                          <p></p>
                          <p></p>
                        </td>
                      </tr>

          </tr>

          <tr>
            <td style="padding:30px;width:25%;vertical-align:middle">
              <img src="./static/semi-3ddet.png" width="240" height="140">
            </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                          <papertitle>Confident semantic ranking loss for part parsing</papertitle>
                          <br>
                          Hongyi Xu, Fengqi Liu, Qianyu Zhou, <strong>Jinkun Hao</strong>, Zhijie Cao, Zhengyang Feng, Lizhuang Ma
              <br>
                                        <em>ICIP</em>, 2021 
                          <br>
                          <a href="https://ieeexplore.ieee.org/abstract/document/9506421">paper</a>
                          <br>
                          <p></p>
                        </td>
                      </tr>

          </tr>

          

          <tr>
            <td style="padding:30px;width:25%;vertical-align:middle">
              <img src="./static/Confident_Semantic.png" width="240" height="140">
            </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                          <papertitle>Confident Semantic Ranking Loss for Part Parsing</papertitle>
                          <br>
                          Xin Tan, Jiachen Xu, Zhou Ye, <strong>Jinkun Hao</strong>, Lizhuang Ma
              <br>
                                        <em>Arxiv</em>, 2024 
                          <br>
                          <a href="https://ieeexplore.ieee.org/abstract/document/9428332">paper</a>
                          <br>
                          <p></p>
                        </td>
                      </tr>

          </tr>
                                                                                   
                                                                                       
                                                                                       
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">Thanks to <a href="https://jonbarron.info/"> Jon Barron</a> for sharing the code of his personal webpage.</p>
              <p></p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:40%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td>
              <script type="text/javascript" id="mapmyvisitors" src="//mapmyvisitors.com/map.js?d=6xDPJQouMX4a95j02wAf89ULZpShwp_PPqYQ_earIQc&cl=ffffff&w=a"></script>
            </td>
          </tr>
        </tbody></table>

      </td>
    </tr>
  </tbody></table>
  


